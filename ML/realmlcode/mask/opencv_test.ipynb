{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 全局阈值\n",
    "def threshold_demo(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # ret, binary = cv2.threshold(gray,0,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    # ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_TRIANGLE)\n",
    "    # ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_TRUNC)\n",
    "    ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    print(\"阈值：\", ret)\n",
    "    cv2.imshow(\"binary\", binary)\n",
    "\n",
    "\n",
    "# 局部阈值\n",
    "def local_threshold(image):\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGRA2GRAY)\n",
    "    # binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,25,10)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 25, 10)\n",
    "    cv2.imshow(\"binary \", binary)\n",
    "\n",
    "\n",
    "def custom_threshold(image):\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGRA2GRAY)\n",
    "    h, w = gray.shape[:2]\n",
    "    m = np.reshape(gray, [1, w*h])\n",
    "    mean = m.sum()/(w*h)\n",
    "    # binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,25,10)\n",
    "    ret, binary = cv2.threshold(gray, mean, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"binary \", binary)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    img = cv2.imread(\"mask4.jpg\")\n",
    "    cv2.namedWindow(\"input image\", cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow(\"input image\", img)\n",
    "    custom_threshold(img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input INPUT] [--prototxt PROTOTXT]\n",
      "                             [--caffemodel CAFFEMODEL] [--width WIDTH]\n",
      "                             [--height HEIGHT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Administrator\\AppData\\Roaming\\jupyter\\runtime\\kernel-ed8c6a18-1cb2-44a0-8a36-718447527038.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import argparse\n",
    " \n",
    "parser = argparse.ArgumentParser(\n",
    "        description='This sample shows how to define custom OpenCV deep learning layers in Python. '\n",
    "                    'Holistically-Nested Edge Detection (https://arxiv.org/abs/1504.06375) neural network '\n",
    "                    'is used as an example model. Find a pre-trained model at https://github.com/s9xie/hed.')\n",
    "parser.add_argument('--input', help='Path to image or video. Skip to capture frames from camera', default='1.jpg')\n",
    "parser.add_argument('--prototxt', help='Path to deploy.prototxt', default='deploy.prototxt')\n",
    "parser.add_argument('--caffemodel', help='Path to hed_pretrained_bsds.caffemodel', default='hed_pretrained_bsds.caffemodel')\n",
    "parser.add_argument('--width', help='Resize input image to a specific width', default=500, type=int)\n",
    "parser.add_argument('--height', help='Resize input image to a specific height', default=500, type=int)\n",
    "args = parser.parse_args()\n",
    " \n",
    "#! [CropLayenr]\n",
    "class CropLayer(object):\n",
    "    def __init__(self, params, blobs):\n",
    "        self.xstart = 0\n",
    "        self.xend = 0\n",
    "        self.ystart = 0\n",
    "        self.yend = 0\n",
    "    \n",
    "    # Our layer receives two inputs. We need to crop the first input blob\n",
    "    # to match a shape of the second one (keeping batch size and number of channels)\n",
    "    def getMemoryShapes(self, inputs):\n",
    "        inputShape, targetShape = inputs[0], inputs[1]\n",
    "        batchSize, numChannels = inputShape[0], inputShape[1]\n",
    "        height, width = targetShape[2], targetShape[3]\n",
    " \n",
    "        #self.ystart = (inputShape[2] - targetShape[2]) / 2\n",
    "        #self.xstart = (inputShape[3] - targetShape[3]) / 2\n",
    " \n",
    " \n",
    "        self.ystart = int((inputShape[2] - targetShape[2]) / 2)\n",
    "        self.xstart = int((inputShape[3] - targetShape[3]) / 2)\n",
    " \n",
    "        self.yend = self.ystart + height\n",
    "        self.xend = self.xstart + width\n",
    " \n",
    "        return [[batchSize, numChannels, height, width]]\n",
    " \n",
    "    def forward(self, inputs):\n",
    "        return [inputs[0][:,:,self.ystart:self.yend,self.xstart:self.xend]]\n",
    "#! [CropLayer]\n",
    " \n",
    "#! [Register]\n",
    "cv.dnn_registerLayer('Crop', CropLayer)\n",
    "#! [Register]\n",
    " \n",
    "# Load the model.\n",
    "net = cv.dnn.readNet(cv.samples.findFile(args.prototxt), cv.samples.findFile(args.caffemodel))\n",
    " \n",
    "kWinName = 'Holistically-Nested Edge Detection'\n",
    "cv.namedWindow('Input', cv.WINDOW_NORMAL)\n",
    "cv.namedWindow(kWinName, cv.WINDOW_NORMAL)\n",
    " \n",
    " \n",
    "frame=cv.imread('5.jpg')\n",
    " \n",
    " \n",
    "cv.imshow('Input', frame)\n",
    "#cv.waitKey(0)\n",
    " \n",
    "inp = cv.dnn.blobFromImage(frame, scalefactor=1.0, size=(args.width, args.height),\n",
    "                               mean=(104.00698793, 116.66876762, 122.67891434),\n",
    "                               swapRB=False, crop=False)\n",
    "net.setInput(inp)\n",
    " \n",
    "out = net.forward()\n",
    "out = out[0, 0]\n",
    "out = cv.resize(out, (frame.shape[1], frame.shape[0]))\n",
    "cv.imshow(kWinName, out)\n",
    "cv.imwrite('result.png',out)\n",
    "cv.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
