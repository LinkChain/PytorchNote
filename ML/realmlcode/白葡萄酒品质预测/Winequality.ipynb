{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(bagging_fraction=0.85, boosting='gbdt', boosting_type='gbdt',\n",
      "        class_weight=None, colsample_bytree=1.0, feature_fraction=0.75,\n",
      "        importance_type='split', lambda_l1=2, learning_rate=0.01,\n",
      "        max_depth=5, metric='multi_error', min_child_samples=5,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=3000,\n",
      "        n_jobs=-1, num_class=7, num_leaves=31, num_threads=20,\n",
      "        objective='multiclass', random_state=None, reg_alpha=0.0,\n",
      "        reg_lambda=0.0, seed=99, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=200000, subsample_freq=0, verbose=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Train:  []\n",
      "Val:  []\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from itertools import combinations\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv', header=None, sep=';')\n",
    "test_df = pd.read_csv('data/test.csv', header=None, sep=';')\n",
    "\n",
    "train_df = train_df[train_df[11] != 'quality']\n",
    "lbl = LabelEncoder().fit(train_df[11])\n",
    "train_df[11] = lbl.transform(train_df[11])\n",
    "\n",
    "for a, b in combinations([0,1,2,3,4,7,8,9,10], 2):\n",
    "    train_df[str(a) + '_' + str(b)] = train_df[a].astype(float) + train_df[b].astype(float)\n",
    "    train_df[str(a) + '/' + str(b)] = train_df[a].astype(float) / train_df[b].astype(float)\n",
    "    train_df[str(a) + '*' + str(b)] = train_df[a].astype(float) * train_df[b].astype(float)\n",
    "    train_df[str(a) + '/log' + str(b)] = train_df[a].astype(float) / np.log1p(train_df[b].astype(float))\n",
    "    \n",
    "    test_df[str(a) + '_' + str(b)] = test_df[a].astype(float) + test_df[b].astype(float)\n",
    "    test_df[str(a) + '/' + str(b)] = test_df[a].astype(float) / test_df[b].astype(float)\n",
    "    test_df[str(a) + '*' + str(b)] = test_df[a].astype(float) * test_df[b].astype(float)\n",
    "    test_df[str(a) + '/log' + str(b)] = test_df[a].astype(float) / np.log1p(test_df[b].astype(float))\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "n_fold = 10\n",
    "skf = StratifiedKFold(n_splits = n_fold, shuffle = True)\n",
    "eval_fun = roc_auc_score\n",
    "\n",
    "def run_oof(clf, X_train, y_train, X_test, kf):\n",
    "    print(clf)\n",
    "    preds_train = np.zeros((len(X_train), 7), dtype = np.float)\n",
    "    preds_test = np.zeros((len(X_test), 7), dtype = np.float)\n",
    "    train_loss = []; test_loss = []\n",
    "\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(X_train, y_train):\n",
    "        x_tr = X_train[train_index]; x_te = X_train[test_index]\n",
    "        y_tr = y_train[train_index]; y_te = y_train[test_index]\n",
    "        clf.fit(x_tr, y_tr, eval_set = [(x_te, y_te)], early_stopping_rounds = 500, verbose = False)\n",
    "        \n",
    "        # train_loss.append(eval_fun(y_tr, clf.predict_proba(x_tr)[:]))\n",
    "        # test_loss.append(eval_fun(y_te, clf.predict_proba(x_te)[:]))\n",
    "\n",
    "        preds_train[test_index] = clf.predict_proba(x_te)[:]\n",
    "        preds_test += clf.predict_proba(X_test)[:]\n",
    "\n",
    "        # print('{0}: Train {1:0.7f} Val {2:0.7f}/{3:0.7f}'.format(i, train_loss[-1], test_loss[-1], np.mean(test_loss)))\n",
    "        print('-' * 50)\n",
    "        i += 1\n",
    "    print('Train: ', train_loss)\n",
    "    print('Val: ', test_loss)\n",
    "    print('-' * 50)\n",
    "    # print('Train{0:0.5f}_Test{1:0.5f}\\n\\n'.format(np.mean(train_loss), np.mean(test_loss)))\n",
    "    preds_test /= n_fold\n",
    "    return preds_train, preds_test\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'min_child_samples': 5,\n",
    "    'max_depth': 5,\n",
    "    'lambda_l1': 2,\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'n_estimators': 3000,\n",
    "    'metric': 'multi_error',\n",
    "    'num_class': 7,\n",
    "    'feature_fraction': .75,\n",
    "    'bagging_fraction': .85,\n",
    "    'seed': 99,\n",
    "    'num_threads': 20,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "train_pred, test_pred = run_oof(lgb.LGBMClassifier(**params), \n",
    "                                train_df.drop(11, axis=1).values, \n",
    "                                train_df[11].values, \n",
    "                                test_df.values, \n",
    "                                skf)\n",
    "\n",
    "submit = pd.DataFrame()\n",
    "submit[0] = range(len(test_df))\n",
    "submit[1] = lbl.inverse_transform(np.argmax(test_pred, 1))\n",
    "submit.to_csv('lgb.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
